{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwVSUX31zzpk"
      },
      "source": [
        "# Logistic Regression & Calibration — Student Lab\n",
        "\n",
        "We focus on *probabilities*, not just accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NPv5SqgMzzpk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def check(name: str, cond: bool):\n",
        "    if not cond:\n",
        "        raise AssertionError(f'Failed: {name}')\n",
        "    print(f'OK: {name}')\n",
        "\n",
        "rng = np.random.default_rng(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdDUDl9Qzzpl"
      },
      "source": [
        "## Section 0 — Synthetic imbalanced data\n",
        "We simulate logits and labels with imbalance and miscalibration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JaxVibVlzzpl",
        "outputId": "a93a0360-aea5-4d3f-ae27-e6de80f848fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_rate 0.0712\n",
            "OK: in_0_1\n"
          ]
        }
      ],
      "source": [
        "def make_probs(n=5000, base_rate=0.05, logit_scale=1.0, miscalibration=1.0):\n",
        "    # Generate true probabilities via latent logits\n",
        "    z = logit_scale * rng.standard_normal(n)\n",
        "    # shift to get desired base rate approximately\n",
        "    z = z + np.log(base_rate/(1-base_rate))\n",
        "    p_true = 1/(1+np.exp(-z))\n",
        "    y = (rng.random(n) < p_true).astype(int)\n",
        "    # observed model probs are miscalibrated by scaling logits\n",
        "    z_model = miscalibration * z\n",
        "    p_model = 1/(1+np.exp(-z_model))\n",
        "    return y, p_model, p_true\n",
        "\n",
        "y, p_model, p_true = make_probs(miscalibration=2.0)\n",
        "print('base_rate', y.mean())\n",
        "check('in_0_1', np.all((p_model>=0) & (p_model<=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ38lnFpzzpl"
      },
      "source": [
        "## Section 1 — Metrics\n",
        "\n",
        "### Task 1.1: Confusion matrix metrics at a threshold\n",
        "Implement precision, recall, F1 at threshold t.\n",
        "\n",
        "# HINT:\n",
        "- y_hat = (p>=t)\n",
        "- TP/FP/FN\n",
        "\n",
        "**Checkpoint:** Why is accuracy misleading under imbalance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oePJuWzxzzpm",
        "outputId": "26d22c57-98d7-48da-bdcb-e3b27ae6cf24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tp': 2, 'fp': 2, 'fn': 354, 'precision': 0.499999999999875, 'recall': 0.005617977528089872, 'f1': 0.011111111111089075}\n"
          ]
        }
      ],
      "source": [
        "def metrics_at_threshold(y, p, t):\n",
        "    # TODO\n",
        "    y = y.astype(int)\n",
        "    yhat = (p >= t).astype(int)\n",
        "    tp = int(np.sum((y == 1) & (yhat == 1)) )\n",
        "    fp = int(np.sum((y == 0) & (yhat == 1)) )\n",
        "    fn = int(np.sum((y == 1) & (yhat == 0)) )\n",
        "    prec = tp / (tp + fp + 1e-12 )\n",
        "    rec = tp / (tp + fn + 1e-12 )\n",
        "    f1 = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
        "    return {'tp': tp, 'fp': fp, 'fn': fn, 'precision': prec, 'recall': rec, 'f1': f1}\n",
        "\n",
        "m = metrics_at_threshold(y, p_model, t=0.5)\n",
        "print(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLGaDAIlzzpm"
      },
      "source": [
        "### Task 1.2: PR curve area (approx)\n",
        "Compute a simple PR-AUC approximation by sorting thresholds.\n",
        "\n",
        "# HINT:\n",
        "- sort by p desc\n",
        "- compute precision/recall at each cut\n",
        "\n",
        "**Interview Angle:** when is PR-AUC preferable to ROC-AUC?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D9Zjy0wHzzpm",
        "outputId": "9edddddc-3cec-4ecd-dbe3-90c7f10a2670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pr_auc 0.20170158178004188\n",
            "OK: finite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3984714661.py:13: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(y, x))\n"
          ]
        }
      ],
      "source": [
        "def pr_curve(y, p):\n",
        "    # TODO: return arrays (recall, precision)\n",
        "    order = np.argsort(-p)\n",
        "    y_sorted = y[order]\n",
        "    tp = np.cumsum(y_sorted == 1)\n",
        "    fp = np.cumsum(y_sorted == 0)\n",
        "    prec = tp / (tp + fp + 1e-12)\n",
        "    rec = tp / (tp[-1] + 1e-12)\n",
        "    return rec, prec\n",
        "\n",
        "def auc_trapz(x, y):\n",
        "    # TODO\n",
        "     return float(np.trapz(y, x))\n",
        "\n",
        "rec, prec = pr_curve(y, p_model)\n",
        "pr_auc = auc_trapz(rec, prec)\n",
        "print('pr_auc', pr_auc)\n",
        "check('finite', np.isfinite(pr_auc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW3YrqvSzzpm"
      },
      "source": [
        "## Section 2 — Calibration\n",
        "\n",
        "### Task 2.1: Reliability curve + ECE\n",
        "\n",
        "Bin probabilities and compute:\n",
        "- avg predicted prob per bin\n",
        "- empirical accuracy per bin\n",
        "- ECE = sum (bin_weight * |acc - conf|)\n",
        "\n",
        "# HINT:\n",
        "- np.digitize\n",
        "\n",
        "**FAANG gotcha:** model can have good ranking but bad calibration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9fEZdK2Qzzpm",
        "outputId": "26062e40-a021-4c2f-ca69-83ab9a78bac7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ECE 0.056267450617459955\n",
            "OK: ece_finite\n"
          ]
        }
      ],
      "source": [
        "def reliability_bins(y, p, n_bins=10):\n",
        "    # TODO: return (bin_acc, bin_conf, bin_frac)\n",
        "    y = y.astype(int)\n",
        "    edges = np.linspace(0, 1, n_bins + 1)\n",
        "    b = np.digitize(p, edges[1:-1], right=False)\n",
        "    bin_acc = np.zeros(n_bins)\n",
        "    bin_conf = np.zeros(n_bins)\n",
        "    bin_frac = np.zeros(n_bins)\n",
        "    for i in range(n_bins):\n",
        "        mask = (b == i)\n",
        "        if mask.any():\n",
        "            bin_acc[i] = y[mask].mean()\n",
        "            bin_conf[i] = p[mask].mean()\n",
        "            bin_frac[i] = mask.mean()\n",
        "\n",
        "    return bin_acc, bin_conf, bin_frac\n",
        "\n",
        "def ece(bin_acc, bin_conf, bin_frac):\n",
        "    # TODO\n",
        "    return float(np.sum(bin_frac * np.abs(bin_acc - bin_conf)))\n",
        "\n",
        "bin_acc, bin_conf, bin_frac = reliability_bins(y, p_model, n_bins=10)\n",
        "ECE = ece(bin_acc, bin_conf, bin_frac)\n",
        "print('ECE', ECE)\n",
        "check('ece_finite', np.isfinite(ECE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw238mrazzpn"
      },
      "source": [
        "### Task 2.2: Temperature scaling\n",
        "\n",
        "We assume p_model came from logits z_model. Approximate logits via logit(p).\n",
        "Then find temperature T that minimizes NLL on validation split: sigmoid(z/T).\n",
        "\n",
        "# HINT:\n",
        "- logit(p)=log(p/(1-p))\n",
        "- grid search T over [0.5..5]\n",
        "\n",
        "**Checkpoint:** Why does scaling logits preserve ranking?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XfyKWrQ4zzpn",
        "outputId": "c95740de-6399-413d-edeb-e7b072fe8f46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_T 1.969387755102041\n",
            "ECE_before 0.05789031077500049 ECE_after 0.006327853058047911\n"
          ]
        }
      ],
      "source": [
        "def logit(p, eps=1e-12):\n",
        "    p = np.clip(p, eps, 1-eps)\n",
        "    return np.log(p/(1-p))\n",
        "\n",
        "def nll(y, p, eps=1e-12):\n",
        "    p = np.clip(p, eps, 1-eps)\n",
        "    return float(-np.mean(y*np.log(p) + (1-y)*np.log(1-p)))\n",
        "\n",
        "# TODO: split into val and fit T\n",
        "idx = rng.permutation(len(y))\n",
        "val = idx[: len(y)//2]\n",
        "test = idx[len(y)//2:]\n",
        "\n",
        "z = logit(p_model)\n",
        "\n",
        "\n",
        "ts = np.linspace(0.5, 5.0, 50)\n",
        "best_T = None\n",
        "best_loss = float('inf')\n",
        "for T in ts:\n",
        "    pT = 1/(1+np.exp(-(z[val]/T)))\n",
        "    loss = nll(y[val], pT)\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        best_T = T\n",
        "pcal = 1/(1+np.exp(-z[test]/best_T))\n",
        "ECE_before = ece(*reliability_bins(y[test], p_model[test], 10))\n",
        "ECE_after = ece(*reliability_bins(y[test], pcal, 10))\n",
        "\n",
        "print('best_T', best_T)\n",
        "# apply temperature on test\n",
        "p_cal = 1/(1+np.exp(-(z[test]/best_T)))\n",
        "ECE_before = ece(*reliability_bins(y[test], p_model[test], 10))\n",
        "ECE_after = ece(*reliability_bins(y[test], p_cal, 10))\n",
        "print('ECE_before', ECE_before, 'ECE_after', ECE_after)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVvN7Sfnzzpn"
      },
      "source": [
        "## Section 3 — Thresholding with costs\n",
        "\n",
        "### Task 3.1: Pick threshold minimizing cost\n",
        "Cost = c_fp*FP + c_fn*FN\n",
        "\n",
        "# TODO: sweep thresholds and pick best.\n",
        "\n",
        "**Interview Angle:** map model probabilities to business decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "faOk0MLgzzpn",
        "outputId": "c004b570-5c67-417c-b8aa-35800224a75b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t* 0.006 cost 2626.0\n"
          ]
        }
      ],
      "source": [
        "def best_threshold_cost(y, p, c_fp=1.0, c_fn=10.0):\n",
        "    # TODO\n",
        "    ts = np.linspace(0, 1, 501)\n",
        "    best_t = 0.5\n",
        "    best_cost = float('inf')\n",
        "    for t in ts:\n",
        "        y_hat = (p >= t).astype(int)\n",
        "        fp = np.sum((y == 0) & (y_hat == 1))\n",
        "        fn = np.sum((y == 1) & (y_hat == 0))\n",
        "        cost = c_fp * fp + c_fn * fn\n",
        "        if cost < best_cost:\n",
        "            best_cost = cost\n",
        "            best_t = t\n",
        "    return best_t, best_cost\n",
        "\n",
        "t_star, cost_star = best_threshold_cost(y, p_model, c_fp=1.0, c_fn=10.0)\n",
        "print('t*', t_star, 'cost', cost_star)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHKzz8JSzzpn"
      },
      "source": [
        "---\n",
        "## Submission Checklist\n",
        "- All TODOs completed\n",
        "- ECE computed\n",
        "- Temperature scaling applied\n",
        "- Threshold recommendation written\n"
      ]
    }
  ]
}